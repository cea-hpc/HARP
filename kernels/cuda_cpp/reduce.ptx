//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32688072
// Cuda compilation tools, release 12.1, V12.1.105
// Based on NVVM 7.0.1
//

.version 8.1
.target sm_75
.address_size 64

	// .globl	reduce
// _ZZ6reduceE5sdata has been demoted

.visible .entry reduce(
	.param .u64 reduce_param_0,
	.param .u64 reduce_param_1,
	.param .u64 reduce_param_2
)
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<19>;
	// demoted variable
	.shared .align 4 .b8 _ZZ6reduceE5sdata[4096];

	ld.param.u64 	%rd8, [reduce_param_0];
	ld.param.u64 	%rd9, [reduce_param_1];
	ld.param.u64 	%rd10, [reduce_param_2];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32 	%rd11, %r1;
	mov.u32 	%r19, %ctaid.x;
	cvt.u64.u32 	%rd1, %r19;
	mul.wide.u32 	%rd12, %r19, 2048;
	add.s64 	%rd18, %rd12, %rd11;
	setp.ge.u64 	%p1, %rd18, %rd9;
	mov.u32 	%r48, 0;
	@%p1 bra 	$L__BB0_5;

	mov.u32 	%r21, %nctaid.x;
	mul.wide.u32 	%rd3, %r21, 2048;
	cvta.to.global.u64 	%rd4, %rd8;

$L__BB0_2:
	shl.b64 	%rd13, %rd18, 2;
	add.s64 	%rd6, %rd4, %rd13;
	ld.global.u32 	%r22, [%rd6];
	add.s32 	%r48, %r22, %r48;
	add.s64 	%rd14, %rd18, 1024;
	setp.ge.u64 	%p2, %rd14, %rd9;
	@%p2 bra 	$L__BB0_4;

	ld.global.u32 	%r23, [%rd6+4096];
	add.s32 	%r48, %r23, %r48;

$L__BB0_4:
	add.s64 	%rd18, %rd18, %rd3;
	setp.lt.u64 	%p3, %rd18, %rd9;
	@%p3 bra 	$L__BB0_2;

$L__BB0_5:
	shl.b32 	%r24, %r1, 2;
	mov.u32 	%r25, _ZZ6reduceE5sdata;
	add.s32 	%r7, %r25, %r24;
	st.shared.u32 	[%r7], %r48;
	bar.sync 	0;
	setp.gt.u32 	%p4, %r1, 511;
	@%p4 bra 	$L__BB0_7;

	ld.shared.u32 	%r26, [%r7+2048];
	add.s32 	%r48, %r26, %r48;
	st.shared.u32 	[%r7], %r48;

$L__BB0_7:
	bar.sync 	0;
	setp.gt.u32 	%p5, %r1, 255;
	@%p5 bra 	$L__BB0_9;

	ld.shared.u32 	%r27, [%r7+1024];
	add.s32 	%r48, %r27, %r48;
	st.shared.u32 	[%r7], %r48;

$L__BB0_9:
	bar.sync 	0;
	setp.gt.u32 	%p6, %r1, 127;
	@%p6 bra 	$L__BB0_11;

	ld.shared.u32 	%r28, [%r7+512];
	add.s32 	%r48, %r28, %r48;
	st.shared.u32 	[%r7], %r48;

$L__BB0_11:
	bar.sync 	0;
	setp.gt.u32 	%p7, %r1, 63;
	@%p7 bra 	$L__BB0_13;

	ld.shared.u32 	%r29, [%r7+256];
	add.s32 	%r48, %r29, %r48;
	st.shared.u32 	[%r7], %r48;

$L__BB0_13:
	bar.sync 	0;
	setp.gt.u32 	%p8, %r1, 31;
	@%p8 bra 	$L__BB0_15;

	ld.shared.u32 	%r30, [%r7+128];
	add.s32 	%r31, %r30, %r48;
	mov.u32 	%r32, 2;
	mov.u32 	%r33, 31;
	mov.u32 	%r34, 16;
	mov.u32 	%r35, -1;
	shfl.sync.down.b32 	%r36|%p9, %r31, %r34, %r33, %r35;
	add.s32 	%r37, %r36, %r31;
	mov.u32 	%r38, 8;
	shfl.sync.down.b32 	%r39|%p10, %r37, %r38, %r33, %r35;
	add.s32 	%r40, %r39, %r37;
	mov.u32 	%r41, 4;
	shfl.sync.down.b32 	%r42|%p11, %r40, %r41, %r33, %r35;
	add.s32 	%r43, %r42, %r40;
	shfl.sync.down.b32 	%r44|%p12, %r43, %r32, %r33, %r35;
	add.s32 	%r45, %r44, %r43;
	mov.u32 	%r46, 1;
	shfl.sync.down.b32 	%r47|%p13, %r45, %r46, %r33, %r35;
	add.s32 	%r48, %r47, %r45;

$L__BB0_15:
	setp.ne.s32 	%p14, %r1, 0;
	@%p14 bra 	$L__BB0_17;

	cvta.to.global.u64 	%rd15, %rd10;
	shl.b64 	%rd16, %rd1, 2;
	add.s64 	%rd17, %rd15, %rd16;
	st.global.u32 	[%rd17], %r48;

$L__BB0_17:
	ret;

}

